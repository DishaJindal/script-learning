{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import read\n",
    "import prepare_data\n",
    "import input_builder\n",
    "\n",
    "import importlib\n",
    "import model\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 2e-5\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "importlib.reload(input_builder)\n",
    "import os\n",
    "os.environ['TFHUB_CACHE_DIR'] = '/home/djjindal/bert/script-learning'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'dataset/gw_extractions_no_rep_no_fin.pickle'\n",
    "train_dataset = read.read_data_iterator(dataset)\n",
    "features = list(prepare_data.tokenize_if_small_enough(train_dataset,sentences=False,no_context=False))\n",
    "train_set = features[:int(0.8 * len(features))]\n",
    "val_set = features[int(0.8 * len(features)):int(0.9*len(features))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<input_builder.InputFeatures object at 0x7f217531e198>\n"
     ]
    }
   ],
   "source": [
    "print(train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7874"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'output_triple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=model_dir,\n",
    "    save_summary_steps=0,\n",
    "    save_checkpoints_steps=0,\n",
    "    log_step_count_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'output_triple', '_tf_random_seed': None, '_save_summary_steps': 0, '_save_checkpoints_steps': 0, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f218cb7e9b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 15:54:39.952149 139784594450176 tf_logging.py:115] Using config: {'_model_dir': 'output_triple', '_tf_random_seed': None, '_save_summary_steps': 0, '_save_checkpoints_steps': 0, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f218cb7e9b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model_fn = model.model_fn_builder(\n",
    "  num_labels=5,\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=1,\n",
    "  num_warmup_steps=1)\n",
    "\n",
    "train_test_input_fn = input_builder.input_fn_builder(\n",
    "    features=train_set,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False,\n",
    "    candidates=5)\n",
    "val_test_input_fn = input_builder.input_fn_builder(\n",
    "    features=val_set,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False,\n",
    "    candidates=5)\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Evaluating Training Dataset!')\n",
    "# print(estimator.evaluate(input_fn=train_test_input_fn))\n",
    "# print(f'Evaluating Validation Dataset!')\n",
    "# print(estimator.evaluate(input_fn=val_test_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def predict(sentenecs, triples, candidates, entity):\n",
    "    e_dict = dict()\n",
    "    check_dataset = []\n",
    "    e_dict['sentences'] = sentenecs\n",
    "    e_dict['triples'] = triples\n",
    "    e_dict['candidates'] = candidates\n",
    "    e_dict['correct'] = 4\n",
    "    e_dict['entity'] = entity\n",
    "    check_dataset = [e_dict]\n",
    "    predict_set = list(prepare_data.tokenize_if_small_enough(check_dataset, sentences=False))\n",
    "\n",
    "    predict_input_fn = input_builder.input_fn_builder(\n",
    "        features=predict_set,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=False,\n",
    "        drop_remainder=False,\n",
    "        candidates=5)\n",
    "    predictions = estimator.predict(input_fn=predict_input_fn,yield_single_examples=False)\n",
    "\n",
    "    for (i, prediction) in enumerate(predictions):\n",
    "        arr = prediction['probabilities'][0]\n",
    "        prob = [np.exp(arr[0]),np.exp(arr[1]),np.exp(arr[2]),np.exp(arr[3]),np.exp(arr[4])]\n",
    "        total = np.sum(prob)\n",
    "        max= np.max(prob)\n",
    "        ec_dict = check_dataset[i]\n",
    "        print(\"SENTENCE EVENT CHAIN\", ec_dict['sentences'],\"\\n\")\n",
    "        print(\"TRIPLE EVENT CHAIN\", ec_dict['triples'],\"\\n\")\n",
    "        print(\"CANDIDATES\", ec_dict['candidates'],\"\\n\")\n",
    "        print(\"ENTITY\", ec_dict['entity'],\"\\n\")\n",
    "        print(\"PREDICTION\", prediction['labels'], \"with Probability\", np.max(prob),\"\\n\",\"\\n\")\n",
    "        return prediction['labels']\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    print(text1.value, text2.value, text3.value)\n",
    "    print(predict([], text1.value.split('), ('), text2.value.split('), ('), text3.value))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d1f324daaa452bb0b361c79e9aa7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Event Chain')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ba586e502146798a47053bac36fb7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Candidates')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27bddcf572c14d7c845d5443051f3722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Entity')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6f58103dc24e7b9d876771c8c6a0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Predict', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('john','ordered',None),('john','ate','food')] [('john','left',None),('john','stays',None)] John\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:00:58.049337 139784594450176 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:01.308325 139784594450176 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:02.281511 139784594450176 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:03.305676 139784594450176 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:04.038987 139784594450176 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:05.154117 139784594450176 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:05.358907 139784594450176 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:05.858475 139784594450176 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from output_triple/model.ckpt-4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:05.862712 139784594450176 tf_logging.py:115] Restoring parameters from output_triple/model.ckpt-4800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:07.385704 139784594450176 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:07.526106 139784594450176 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE EVENT CHAIN [] \n",
      "\n",
      "TRIPLE EVENT CHAIN [\"[('john','ordered',None),('john','ate','food')]\"] \n",
      "\n",
      "CANDIDATES [\"[('john','left',None),('john','stays',None)]\"] \n",
      "\n",
      "ENTITY John \n",
      "\n",
      "PREDICTION 1 with Probability 0.8150803 \n",
      " \n",
      "\n",
      "1\n",
      "[('john','ordered',None),('john','ate','food'),('john','stood',None)] [('john','left',None),('john','stays',None)] John\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:26.129020 139784594450176 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:30.021843 139784594450176 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:31.023909 139784594450176 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:31.756632 139784594450176 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:32.896042 139784594450176 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:33.694056 139784594450176 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:33.906960 139784594450176 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:34.829629 139784594450176 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from output_triple/model.ckpt-4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:34.833980 139784594450176 tf_logging.py:115] Restoring parameters from output_triple/model.ckpt-4800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:36.471080 139784594450176 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0421 16:01:36.613571 139784594450176 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE EVENT CHAIN [] \n",
      "\n",
      "TRIPLE EVENT CHAIN [\"[('john','ordered',None),('john','ate','food'),('john','stood',None)]\"] \n",
      "\n",
      "CANDIDATES [\"[('john','left',None),('john','stays',None)]\"] \n",
      "\n",
      "ENTITY John \n",
      "\n",
      "PREDICTION 1 with Probability 0.69223154 \n",
      " \n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "from IPython.html import widgets\n",
    "text1 = widgets.Text(description=\"Event Chain\", width=200)\n",
    "text2 = widgets.Text(description=\"Candidates\", width=200)\n",
    "text3 = widgets.Text(description=\"Entity\", width=200)\n",
    "button = widgets.Button(description=\"Predict\")\n",
    "button.on_click(on_button_clicked)\n",
    "display(text1)\n",
    "display(text2)\n",
    "display(text3)\n",
    "display(button)\n",
    "\n",
    "# [('john','ordered',None),('john','ate','food')]\n",
    "# [('john','left',None),('john','stays',None)]\n",
    "\n",
    "# [('john','ordered',None),('john','ate','food'),('john','stood',None)]\n",
    "# [('john','left',None),('john','stays',None)]\n",
    "\n",
    "# [(None, 'took', 'phone call'), (None, 'had', 'something'), (None, 'began', 'to squint')] \n",
    "# [(None, 'broadcast', '(the two previous record-holders'), ('the pennant', 'slammed', None), (None, \"n't imagine\", 'Maris'), (None, 'expressed', 'interest'), (None, 'turned', '68 _')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# common_sense_net = pd.read_hdf('mini.h5')\n",
    "# common_sense_net = common_sense_net[common_sense_net.index.map(lambda x: x.startswith('/c/en/'))]\n",
    "# common_sense_net.index = common_sense_net.index.map(lambda x: x.split('/c/en/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_sense_net.loc['UNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset = list(read.read_data_iterator('dataset/gw_extractions_no_rep_no_fin.pickle'))\n",
    "# train_data = dataset[:int(0.8 * len(features))]\n",
    "# val_data = dataset[int(0.8 * len(features)):int(0.9*len(features))]\n",
    "\n",
    "# check_dataset = []\n",
    "\n",
    "# for i, ec_dict in zip(range(50), val_data):\n",
    "#     check_dataset.append(ec_dict)\n",
    "    \n",
    "# predict_set = list(prepare_data.tokenize_if_small_enough(check_dataset, sentences=False))\n",
    "# predict_input_fn = input_builder.input_fn_builder(\n",
    "#     features=predict_set,\n",
    "#     seq_length=MAX_SEQ_LENGTH,\n",
    "#     is_training=False,\n",
    "#     drop_remainder=False,\n",
    "#     candidates=5)\n",
    "\n",
    "# predictions = estimator.predict(input_fn=predict_input_fn,yield_single_examples=False)\n",
    "# print(\"Predict Set Length\", len(predict_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# for (i, prediction) in enumerate(predictions):\n",
    "#     arr = prediction['probabilities'][0]\n",
    "#     prob = [np.exp(arr[0]),np.exp(arr[1]),np.exp(arr[2]),np.exp(arr[3]),np.exp(arr[4])]\n",
    "#     total = np.sum(prob)\n",
    "#     max= np.max(prob)\n",
    "# #     print(\"arg\", prediction['labels'], \"max \", np.max(prob))\n",
    "#     ec_dict = check_dataset[i]\n",
    "#     print(\"SENTENCE EVENT CHAIN\", ec_dict['sentences'],\"\\n\")\n",
    "#     print(\"TRIPLE EVENT CHAIN\", ec_dict['triples'],\"\\n\")\n",
    "#     print(\"CANDIDATES\", ec_dict['candidates'],\"\\n\")\n",
    "#     print(\"ENTITY\", ec_dict['entity'],\"\\n\")\n",
    "#     print(\"CORRECT\", ec_dict['correct'] + 1,\"\\n\")\n",
    "#     print(\"PREDICTION\", prediction['labels'], \"with Probability\", np.max(prob),\"\\n\",\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e_dict = dict()\n",
    "# check_dataset = []\n",
    "# e_dict['sentences'] = ['The other day, Ettinger unabashedly took\\na phone call in front of a visitor.', 'The caller had something to\\nsell.', 'Then he began to squint, seemingly pondering.'] \n",
    "# e_dict['triples'] = [(None, 'took', 'phone call'), (None, 'had', 'something'), (None, 'began', 'to squint')] \n",
    "# e_dict['candidates'] = [(None, 'broadcast', '(the two previous record-holders'), ('the pennant', 'slammed', None), (None, \"n't imagine\", 'Maris'), (None, 'expressed', 'interest'), (None, 'turned', '68 _')] \n",
    "# e_dict['correct'] = 4\n",
    "# e_dict['entity'] = \"Ettinger\"\n",
    "# check_dataset = [e_dict]\n",
    "# predict_set = list(prepare_data.tokenize_if_small_enough(check_dataset, sentences=False))\n",
    "\n",
    "# predict_input_fn = input_builder.input_fn_builder(\n",
    "#     features=predict_set,\n",
    "#     seq_length=MAX_SEQ_LENGTH,\n",
    "#     is_training=False,\n",
    "#     drop_remainder=False,\n",
    "#     candidates=5)\n",
    "# predictions = estimator.predict(input_fn=predict_input_fn,yield_single_examples=False)\n",
    "\n",
    "# for (i, prediction) in enumerate(predictions):\n",
    "#     arr = prediction['probabilities'][0]\n",
    "#     prob = [np.exp(arr[0]),np.exp(arr[1]),np.exp(arr[2]),np.exp(arr[3]),np.exp(arr[4])]\n",
    "#     total = np.sum(prob)\n",
    "#     max= np.max(prob)\n",
    "#     ec_dict = check_dataset[i]\n",
    "#     print(\"SENTENCE EVENT CHAIN\", ec_dict['sentences'],\"\\n\")\n",
    "#     print(\"TRIPLE EVENT CHAIN\", ec_dict['triples'],\"\\n\")\n",
    "#     print(\"CANDIDATES\", ec_dict['candidates'],\"\\n\")\n",
    "#     print(\"ENTITY\", ec_dict['entity'],\"\\n\")\n",
    "#     print(\"CORRECT\", 4,\"\\n\")\n",
    "#     print(\"PREDICTION\", prediction['labels'], \"with Probability\", np.max(prob),\"\\n\",\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

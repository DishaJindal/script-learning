{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0422 11:07:12.826114 139994184660736 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 11:07:15.694695 139994184660736 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import read\n",
    "import prepare_data\n",
    "import input_builder\n",
    "\n",
    "import importlib\n",
    "import model\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 2e-5\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "importlib.reload(input_builder)\n",
    "import os\n",
    "os.environ['TFHUB_CACHE_DIR'] = '/home/djjindal/bert/script-learning'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "model_dir = 'output_sentence'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<input_builder.InputFeatures object at 0x7f5250f210b8>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7874"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'dataset/gw_extractions_no_rep_no_fin.pickle'\n",
    "train_dataset = read.read_data_iterator(dataset)\n",
    "features = list(prepare_data.tokenize_if_small_enough(train_dataset,sentences=True,no_context=False))\n",
    "train_set = features[:int(0.8 * len(features))]\n",
    "val_set = features[int(0.8 * len(features)):int(0.9*len(features))]\n",
    "print(train_set[0])\n",
    "len(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'output_sentence', '_tf_random_seed': None, '_save_summary_steps': 0, '_save_checkpoints_steps': 0, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5250ab42b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 11:07:34.249150 139994184660736 tf_logging.py:115] Using config: {'_model_dir': 'output_sentence', '_tf_random_seed': None, '_save_summary_steps': 0, '_save_checkpoints_steps': 0, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5250ab42b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=model_dir,\n",
    "    save_summary_steps=0,\n",
    "    save_checkpoints_steps=0,\n",
    "    log_step_count_steps=100)\n",
    "\n",
    "model_fn = model.model_fn_builder(\n",
    "  num_labels=5,\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=1,\n",
    "  num_warmup_steps=1)\n",
    "\n",
    "train_test_input_fn = input_builder.input_fn_builder(\n",
    "    features=train_set,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False,\n",
    "    candidates=5)\n",
    "\n",
    "val_test_input_fn = input_builder.input_fn_builder(\n",
    "    features=val_set,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False,\n",
    "    candidates=5)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def predict(sentenecs, triples, candidates, entity):\n",
    "    e_dict = dict()\n",
    "    check_dataset = []\n",
    "    e_dict['sentences'] = sentenecs\n",
    "    e_dict['triples'] = triples\n",
    "    e_dict['candidates'] = candidates\n",
    "    e_dict['correct'] = 4\n",
    "    e_dict['entity'] = entity\n",
    "    check_dataset = [e_dict]\n",
    "    predict_set = list(prepare_data.tokenize_if_small_enough(check_dataset, sentences=True))\n",
    "\n",
    "    predict_input_fn = input_builder.input_fn_builder(\n",
    "        features=predict_set,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=False,\n",
    "        drop_remainder=False,\n",
    "        candidates=5)\n",
    "    predictions = estimator.predict(input_fn=predict_input_fn,yield_single_examples=False)\n",
    "\n",
    "    for (i, prediction) in enumerate(predictions):\n",
    "        arr = prediction['probabilities'][0]\n",
    "        prob = [np.exp(arr[0]),np.exp(arr[1]),np.exp(arr[2]),np.exp(arr[3]),np.exp(arr[4])]\n",
    "        total = np.sum(prob)\n",
    "        max= np.max(prob)\n",
    "        ec_dict = check_dataset[i]\n",
    "        print(\"SENTENCE EVENT CHAIN\", ec_dict['sentences'],\"\\n\")\n",
    "        print(\"TRIPLE EVENT CHAIN\", ec_dict['triples'],\"\\n\")\n",
    "        print(\"CANDIDATES\", ec_dict['candidates'],\"\\n\")\n",
    "        print(\"ENTITY\", ec_dict['entity'],\"\\n\")\n",
    "        print(prob)\n",
    "        print(\"PREDICTION\", prediction['labels'], \"with Probability\", np.max(prob),\"\\n\",\"\\n\")\n",
    "        return prediction['labels']\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    print(text1.value, text2.value, text3.value)\n",
    "    print(predict(text1.value.split('), ('),[], text2.value.split('), ('), text3.value))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djjindal/venvs/TF-1.3/lib/python3.6/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9d77b350ce4aa6a9a078c8f5c1954f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Event Chain')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4049b01bf35844cf9085a430388d1fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Candidates')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb491957406432681007229e1fd668b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Entity')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e42e1ba71694ec4a8c8576eef634492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Predict', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We felt like fools, until our guide assured us that more intrepid tourists had met ghastly fates.', 'We heaved sighs of relief and reassured ourselves that no other activity on our trip would prove so nerve-wracking.', 'We had yet to reach Lake Atitlan, where a volcano beckoned us toward its cloud-shrouded apex.']  [('it', 'took', None), ('Guatemala City', 'broke', None), (None, 'had', 'Rickety'), ('September', 'averaging', None), (None, 'clog', 'the\\npages')]  us\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 11:09:18.397916 139994184660736 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 11:09:21.987322 139994184660736 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 11:09:22.949463 139994184660736 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 11:09:23.647374 139994184660736 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 11:09:24.689357 139994184660736 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 11:09:25.448302 139994184660736 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 11:09:25.622881 139994184660736 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 11:09:26.467387 139994184660736 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from output_sentence/model.ckpt-4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 11:09:26.472372 139994184660736 tf_logging.py:115] Restoring parameters from output_sentence/model.ckpt-4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 11:09:28.196173 139994184660736 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 11:09:28.371074 139994184660736 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE EVENT CHAIN [\"['We felt like fools, until our guide assured us that more intrepid tourists had met ghastly fates.', 'We heaved sighs of relief and reassured ourselves that no other activity on our trip would prove so nerve-wracking.', 'We had yet to reach Lake Atitlan, where a volcano beckoned us toward its cloud-shrouded apex.'] \"] \n",
      "\n",
      "TRIPLE EVENT CHAIN [] \n",
      "\n",
      "CANDIDATES [\"[('it', 'took', None\", \"'Guatemala City', 'broke', None\", \"None, 'had', 'Rickety'\", \"'September', 'averaging', None\", \"None, 'clog', 'the\\\\npages')] \"] \n",
      "\n",
      "ENTITY us \n",
      "\n",
      "[0.0010449102, 0.4635781, 0.4269606, 0.05135711, 0.057059262]\n",
      "PREDICTION 1 with Probability 0.4635781 \n",
      " \n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "from IPython.html import widgets\n",
    "text1 = widgets.Text(description=\"Event Chain\", width=200)\n",
    "text2 = widgets.Text(description=\"Candidates\", width=200)\n",
    "text3 = widgets.Text(description=\"Entity\", width=200)\n",
    "button = widgets.Button(description=\"Predict\")\n",
    "button.on_click(on_button_clicked)\n",
    "display(text1)\n",
    "display(text2)\n",
    "display(text3)\n",
    "display(button)\n",
    "\n",
    "# ['We felt like fools, until our guide assured us that more intrepid tourists had met ghastly fates.', 'We heaved sighs of relief and reassured ourselves that no other activity on our trip would prove so nerve-wracking.', 'We had yet to reach Lake Atitlan, where a volcano beckoned us toward its cloud-shrouded apex.']\n",
    "# [('it', 'took', None), ('Guatemala City', 'broke', None), (None, 'had', 'Rickety'), ('September', 'averaging', None), (None, 'clog', 'the\\npages')] \n",
    "# us\n",
    "\n",
    "# [('john','ordered',None),('john','ate','food')]\n",
    "# [('john','left',None),('john','stays',None)]\n",
    "\n",
    "# [('john','ordered',None),('john','paid',None),('john','ate','food')]\n",
    "# [('john','left',None),('john','stays',None)]\n",
    "\n",
    "# [(None, 'took', 'phone call'), (None, 'had', 'something'), (None, 'began', 'to squint')] \n",
    "# [(None, 'broadcast', '(the two previous record-holders'), ('the pennant', 'slammed', None), (None, \"n't imagine\", 'Maris'), (None, 'expressed', 'interest'), (None, 'turned', '68 _')] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djjindal/venvs/TF-1.3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: generator 'read_data_iterator' raised StopIteration\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 01:10:58.482223 140256587015936 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 01:11:02.343075 140256587015936 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 01:11:03.677322 140256587015936 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 01:11:05.063902 140256587015936 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 01:11:05.819777 140256587015936 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 01:11:07.230774 140256587015936 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 01:11:07.430206 140256587015936 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 01:11:07.946462 140256587015936 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from output_sentence/model.ckpt-4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 01:11:07.951207 140256587015936 tf_logging.py:115] Restoring parameters from output_sentence/model.ckpt-4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 01:11:09.633590 140256587015936 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 01:11:09.806243 140256587015936 tf_logging.py:115] Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "dataset = list(read.read_data_iterator('dataset/gw_extractions_no_rep_no_fin.pickle'))\n",
    "train_data = dataset[:int(0.8 * len(features))]\n",
    "val_data = dataset[int(0.8 * len(features)):]\n",
    "\n",
    "check_dataset = []\n",
    "\n",
    "for i, ec_dict in zip(range(1000), val_data):\n",
    "    check_dataset.append(ec_dict)\n",
    "    \n",
    "predict_set = list(prepare_data.tokenize_if_small_enough(check_dataset,sentences=True,no_context=False))\n",
    "predict_input_fn = input_builder.input_fn_builder(\n",
    "    features=predict_set,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False,\n",
    "    candidates=5)\n",
    "\n",
    "predictions = estimator.predict(input_fn=predict_input_fn,yield_single_examples=False)\n",
    "predictions_list = list(predictions)\n",
    "for (i, prediction) in enumerate(predictions):\n",
    "    arr = prediction['probabilities'][0]\n",
    "    prob = [np.exp(arr[0]),np.exp(arr[1]),np.exp(arr[2]),np.exp(arr[3]),np.exp(arr[4])]\n",
    "    total = np.sum(prob)\n",
    "    max= np.max(prob)\n",
    "    ec_dict = check_dataset[i]\n",
    "    print(\"SENTENCE EVENT CHAIN\", ec_dict['sentences'],\"\\n\")\n",
    "    print(\"TRIPLE EVENT CHAIN\", ec_dict['triples'],\"\\n\")\n",
    "    print(\"CANDIDATES\", ec_dict['candidates'],\"\\n\")\n",
    "    print(\"ENTITY\", ec_dict['entity'],\"\\n\")\n",
    "    print(prob)\n",
    "    print(\"CORRECT\", ec_dict['correct'] + 1,\"\\n\")\n",
    "    print(\"PREDICTION\", prediction['labels']+1, \"with Probability\", np.max(prob),\"\\n\",\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "19\n",
      "49\n",
      "77\n",
      "118\n",
      "162\n",
      "220\n",
      "241\n",
      "298\n",
      "365\n",
      "533\n",
      "539\n",
      "555\n",
      "583\n",
      "615\n",
      "651\n",
      "681\n",
      "696\n",
      "727\n",
      "836\n",
      "841\n",
      "901\n",
      "933\n",
      "947\n"
     ]
    }
   ],
   "source": [
    "bad = []\n",
    "for i, c in enumerate(check_dataset):\n",
    "    r = list(prepare_data.tokenize_if_small_enough([c],sentences=True,no_context=False))\n",
    "    if not r:\n",
    "        print(i)\n",
    "        bad.append(i)\n",
    "good_gt = [c for i, c in enumerate(check_dataset) if i not in bad]\n",
    "pred_df = pd.DataFrame.from_dict({'predictions':predictions_list, 'dataset':good_gt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7346311475409836\n"
     ]
    }
   ],
   "source": [
    "pred_df['pred_label'] = pred_df.predictions.apply(lambda x: x['labels'] - 1)\n",
    "pred_df['gt_label'] = pred_df.dataset.apply(lambda x: x['correct'])\n",
    "pred_df['correct_pred'] = pred_df.apply(lambda s: s.pred_label == s.gt_label, axis=1)\n",
    "print(pred_df.correct_pred.sum()/len(pred_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_pickle(\"./sentence1000_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
